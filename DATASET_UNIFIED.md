# Dataset Source - UNIFIED DOCUMENTATION

**Version:** FINAL 1.0
**Date:** 2025-01-21
**Status:** ‚úÖ ALL FILES UPDATED

---

## ‚úÖ FINAL DECISION: Use Kaggle Dataset

After reviewing all documentation, we have **unified on using Kaggle as the primary data source**.

### Official Dataset

```
Source:   Kaggle
Dataset:  akshaybe/updated-mimic-iv
URL:      https://www.kaggle.com/datasets/akshaybe/updated-mimic-iv
Size:     ~5 GB (cleaned)
Access:   PUBLIC - No approval required
```

### Download Method

```python
import kagglehub
path = kagglehub.dataset_download("akshaybe/updated-mimic-iv")
```

Or use provided script:
```bash
python scripts/download_data.py
```

---

## üìù Files Updated

All documentation has been updated to reflect Kaggle as primary source:

### ‚úÖ Core Documentation
- [x] `CLAUDE.md` - Development guide (updated)
- [x] `DATA_SOURCE.md` - Complete dataset documentation (NEW)
- [x] `DATABASE_SCHEMA.md` - Schema design (updated)
- [x] `REQUIREMENTS.md` - FR-DATA-001 updated
- [x] `TASK_BREAKDOWN.md` - Task 2.1 updated
- [x] `README.md` - Quick start guide (NEW)

### ‚úÖ Scripts
- [x] `scripts/download_data.py` - Kaggle download script (NEW)

### ‚ö†Ô∏è Files NOT Updated (still reference PhysioNet)
These files contain reference implementations and don't need updating:
- `ARCHITECTURE_DESIGN.md` - Generic architecture (doesn't specify source)
- `MODEL_ALIGNMENT.md` - References research papers using MIMIC-III/IV
- `AGENT_HOOKS_*.md` - Generic agent design
- `UI_BACKEND_WIRING.md` - API patterns (source-agnostic)
- `IMPLEMENTED_VS_VISION.md` - Implementation status

---

## üéØ Why Kaggle (Not PhysioNet)?

| Aspect | Kaggle ‚úÖ | PhysioNet ‚ùå |
|--------|----------|-------------|
| **Access** | Instant, public | 1-3 days approval |
| **Training** | None | CITI course (2h) |
| **Size** | 5 GB | 15 GB |
| **Quality** | Pre-cleaned | Raw |
| **Setup** | `pip install kagglehub` | Account + approval |
| **Speed** | Fast (Kaggle CDN) | Slower |

**Result:** Kaggle is **3x faster** to get started and requires **no waiting**.

---

## üìä Dataset Contents

### 6 Core Tables (from Kaggle)

```
‚úì icustays.csv       - ICU stay metadata (~73K stays)
‚úì patients.csv       - Patient demographics
‚úì admissions.csv     - Hospital admissions
‚úì chartevents.csv    - Vital signs (~200M rows)
‚úì labevents.csv      - Lab results (~100M rows)
‚úì diagnoses_icd.csv  - ICD-10 diagnoses
```

### Item IDs (Same as MIMIC-IV)

**Vitals:**
- 220045 = Heart Rate
- 220179 = Systolic BP
- 220180 = Diastolic BP
- 223761 = Temperature
- 220210 = Respiratory Rate
- 220277 = SpO2

**Labs:**
- 51301 = WBC
- 50813 = Lactate
- 50912 = Creatinine
- 50971 = Potassium
- 50983 = Sodium
- 51265 = Platelets
- ... (see DATABASE_SCHEMA.md)

---

## üöÄ Quick Start (After Unified Update)

### Step 1: Install kagglehub

```bash
pip install kagglehub
```

### Step 2: Setup Kaggle Credentials

```bash
# 1. Go to https://www.kaggle.com/settings
# 2. Click "Create New API Token"
# 3. Place kaggle.json in ~/.kaggle/

mkdir -p ~/.kaggle
mv ~/Downloads/kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json
```

### Step 3: Download Dataset

```bash
python scripts/download_data.py
```

**Output:**
```
[1/3] Downloading dataset from Kaggle...
‚úì Download complete!
  Location: /home/user/.cache/kagglehub/datasets/...

[2/3] Verifying dataset structure...
  ‚úì icustays.csv           (45.2 MB)
  ‚úì patients.csv           (12.3 MB)
  ‚úì admissions.csv         (28.1 MB)
  ‚úì chartevents.csv        (2,456.8 MB)
  ‚úì labevents.csv          (1,234.5 MB)
  ‚úì diagnoses_icd.csv      (18.7 MB)

Dataset location: /path/to/data
Total size: 3,795.6 MB (3.70 GB)

Next steps:
  1. Ingest data into PostgreSQL:
     python scripts/ingest_mimic_iv.py --data-path /path/to/data
```

### Step 4: Ingest to Database

```bash
# Start PostgreSQL
docker-compose up -d postgres

# Ingest data
python scripts/ingest_mimic_iv.py --data-path /path/from/step3

# Verify
docker exec mediai_postgres_1 psql -U postgres -d mimic_iv \
  -c "SELECT COUNT(*) FROM raw.icustays;"
# Expected: ~73,000
```

---

## üîç Verification Checklist

After updates, verify all files reference Kaggle:

```bash
# Search for old PhysioNet references
grep -r "PhysioNet approval" *.md
# Should return ONLY DATA_SOURCE.md (comparison section)

grep -r "CITI training" *.md
# Should return ONLY DATA_SOURCE.md (comparison section)

grep -r "15GB" *.md
# Should return ONLY comparison contexts, not as primary source

# Search for correct Kaggle references
grep -r "akshaybe/updated-mimic-iv" *.md
# Should return: CLAUDE.md, DATA_SOURCE.md, REQUIREMENTS.md, README.md

grep -r "kagglehub" *.md scripts/*.py
# Should return: multiple files with correct import
```

---

## üìö Documentation Hierarchy

```
README.md (Quick Start)
    ‚Üì
CLAUDE.md (Development Guide)
    ‚Üì
DATA_SOURCE.md (Complete Dataset Info)
    ‚Üì
DATABASE_SCHEMA.md (Schema Design)
```

**For developers:**
1. Start with `README.md` for overview
2. Read `CLAUDE.md` for complete dev guide
3. Reference `DATA_SOURCE.md` for dataset details
4. Use `DATABASE_SCHEMA.md` for schema queries

---

## ‚úÖ Changes Summary

### Added Files
1. `DATA_SOURCE.md` - Complete dataset documentation
2. `README.md` - Project README with Kaggle quick start
3. `scripts/download_data.py` - Kaggle download script
4. `DATASET_UNIFIED.md` - This file (unification summary)

### Updated Files
1. `CLAUDE.md`
   - Data source section updated to Kaggle
   - Added reference to DATA_SOURCE.md
   - Updated database schema section

2. `REQUIREMENTS.md`
   - FR-DATA-001 updated (Kaggle source, 5GB, 6 tables)
   - Added reference to DATA_SOURCE.md

3. `TASK_BREAKDOWN.md`
   - Task 2.1 completely rewritten for Kaggle
   - Removed PhysioNet approval steps
   - Updated to 30-minute task (vs 2-5 days)

4. `DATABASE_SCHEMA.md`
   - Added "Kaggle MIMIC-IV optimized" in header
   - Section 7: Migration from PhysioNet to Kaggle
   - Confirmed same item IDs work

### Not Changed (Intentional)
- `ARCHITECTURE_DESIGN.md` - Generic architecture
- `MODEL_ALIGNMENT.md` - Research references
- `AGENT_HOOKS_*.md` - Generic agent patterns
- `UI_BACKEND_WIRING.md` - Source-agnostic API design

---

## üéì Key Takeaways

1. **Kaggle is primary source** - No PhysioNet approval needed
2. **Same MIMIC-IV schema** - Item IDs match official MIMIC-IV
3. **Pre-cleaned data** - Less preprocessing needed
4. **5GB vs 15GB** - Faster download and ingestion
5. **All docs updated** - Single source of truth

---

## üö® Important Notes

### For Future Contributors

When adding new documentation:
1. Always reference `akshaybe/updated-mimic-iv` from Kaggle
2. Do NOT mention PhysioNet approval requirements
3. Use `scripts/download_data.py` for download instructions
4. Reference `DATA_SOURCE.md` for complete details

### For Code Changes

When updating data ingestion code:
1. Expect 6 tables (not 20+)
2. Use Kaggle item IDs (same as MIMIC-IV)
3. Data is pre-cleaned (fewer outliers)
4. Size is ~5GB (not 15GB)

---

## ‚úÖ Unified Status: COMPLETE

All documentation now consistently references:
- **Primary source:** Kaggle `akshaybe/updated-mimic-iv`
- **Access:** Public, instant download
- **Method:** `kagglehub.dataset_download()`
- **Script:** `scripts/download_data.py`

**No more PhysioNet approval waiting! üéâ**

---

**Last Updated:** 2025-01-21
**Verified By:** Project Lead
**Status:** ‚úÖ FINAL - Ready for development
